{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/apple/miniconda3/envs/cta-dev/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3062: DtypeWarning: Columns (7) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv(\"../data/train.csv\")\n",
    "store = pd.read_csv(\"../data/store.csv\")\n",
    "\n",
    "merged_train_store = pd.merge(store, train, on='Store', how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Drop rows and Cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove column with zero sales\n",
    "zero_sales_mask = (merged_train_store.Sales == 0) | merged_train_store.Sales.isnull()\n",
    "nonzero_sales = merged_train_store.loc[~zero_sales_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the Customers column\n",
    "nonzero_sales = nonzero_sales.drop(['Customers', 'Open'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert date to datetime\n",
    "nonzero_sales.Date = pd.to_datetime(nonzero_sales.Date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop NULLs from some columns\n",
    "nonzero_sales = nonzero_sales.dropna(axis=0, subset=['CompetitionDistance','StateHoliday','SchoolHoliday','Promo'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Missing value imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Store                             0\n",
       "StoreType                         0\n",
       "Assortment                        0\n",
       "CompetitionDistance               0\n",
       "CompetitionOpenSinceMonth    143023\n",
       "CompetitionOpenSinceYear     143023\n",
       "Promo2                            0\n",
       "Promo2SinceWeek              222774\n",
       "Promo2SinceYear              222774\n",
       "PromoInterval                222774\n",
       "Date                              0\n",
       "DayOfWeek                     13497\n",
       "Sales                             0\n",
       "Promo                             0\n",
       "StateHoliday                      0\n",
       "SchoolHoliday                     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop NULLS from some\n",
    "nonzero_sales.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out columns where the competitionsinceyear is below 1990\n",
    "mask_1990 = nonzero_sales.CompetitionOpenSinceYear < 1990\n",
    "nonzero_sales = nonzero_sales[~mask_1990]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impute CompetitionOpenSinceMonth / CompetitionOpenSinceYear\n",
    "mean_impute_cols = ['CompetitionOpenSinceMonth', 'CompetitionOpenSinceYear']\n",
    "mean_impute = np.floor(nonzero_sales[mean_impute_cols].mean())\n",
    "nonzero_sales[mean_impute_cols] = nonzero_sales[mean_impute_cols].fillna(mean_impute, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impute Promo2SinceWeek/Year\n",
    "zero_impute_cols = ['Promo2SinceWeek', 'Promo2SinceYear']\n",
    "zero_impute = 0\n",
    "nonzero_sales[zero_impute_cols] = nonzero_sales[zero_impute_cols].fillna(zero_impute, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impute Promo Interval\n",
    "string_impute_cols = ['PromoInterval']\n",
    "string_impute = 'unavailable'\n",
    "nonzero_sales[string_impute_cols] = nonzero_sales[string_impute_cols].fillna(string_impute, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store\n",
    "store_freq = Counter(nonzero_sales.Store)\n",
    "nonzero_sales['Store_fenc'] = nonzero_sales.Store.map(store_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# StoreType\n",
    "nonzero_sales = pd.get_dummies(nonzero_sales, columns=['StoreType'], drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assortment\n",
    "enc_assort = {'a':1, 'b':2, 'c':3}\n",
    "nonzero_sales['Assortment_orenc'] = nonzero_sales.Assortment.map(enc_assort)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Date\n",
    "nonzero_sales['Month'] = nonzero_sales['Date'].dt.month\n",
    "nonzero_sales['DayOfMonth'] = nonzero_sales['Date'].dt.day\n",
    "nonzero_sales['Year'] = nonzero_sales['Date'].dt.year\n",
    "nonzero_sales['DayOfWeek'] = nonzero_sales['Date'].dt.dayofweek\n",
    "nonzero_sales['WeekOfYear'] = nonzero_sales['Date'].dt.weekofyear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Store                        0\n",
       "Assortment                   0\n",
       "CompetitionDistance          0\n",
       "CompetitionOpenSinceMonth    0\n",
       "CompetitionOpenSinceYear     0\n",
       "Promo2                       0\n",
       "Promo2SinceWeek              0\n",
       "Promo2SinceYear              0\n",
       "PromoInterval                0\n",
       "Date                         0\n",
       "DayOfWeek                    0\n",
       "Sales                        0\n",
       "Promo                        0\n",
       "StateHoliday                 0\n",
       "SchoolHoliday                0\n",
       "Store_fenc                   0\n",
       "StoreType_b                  0\n",
       "StoreType_c                  0\n",
       "StoreType_d                  0\n",
       "Assortment_orenc             0\n",
       "Month                        0\n",
       "DayOfMonth                   0\n",
       "Year                         0\n",
       "WeekOfYear                   0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nonzero_sales.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CompetitionOpenSince[Month / Year]\n",
    "nonzero_sales['CompetitionOpenSincePeriod'] = (12 * (nonzero_sales['Year'] -\n",
    "                                                     nonzero_sales['CompetitionOpenSinceYear']\n",
    "                                                    )\n",
    "                                              ) + (nonzero_sales['Month'] - \n",
    "                                                   nonzero_sales['CompetitionOpenSinceMonth']\n",
    "                                                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Promo2Since[Week / Year]\n",
    "nonzero_sales['Promo2SincePeriod'] = (52 * (nonzero_sales['Year'] - \n",
    "                                            nonzero_sales['Promo2SinceYear']\n",
    "                                           ) + (nonzero_sales['WeekOfYear'] - \n",
    "                                                nonzero_sales['Promo2SinceWeek']\n",
    "                                               )\n",
    "                                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PromoInterval\n",
    "nonzero_sales = pd.get_dummies(nonzero_sales, \n",
    "                               columns=['PromoInterval'], \n",
    "                               drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# StateHoliday\n",
    "state_holiday_enc = {'0':0, 0.0:0, 'a':1, 'b':1, 'c':1}\n",
    "nonzero_sales['StateHoliday_benc'] = nonzero_sales.StateHoliday.map(state_holiday_enc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Drop the encoded columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_encoded_cols = ['Store', 'Assortment', 'Date', \n",
    "                     'CompetitionOpenSinceMonth', 'CompetitionOpenSinceYear', \n",
    "                     'Promo2SinceWeek', 'Promo2SinceYear', \n",
    "                     'StateHoliday']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = nonzero_sales.drop(drop_encoded_cols, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = final_df.drop('Sales', axis=1)\n",
    "y = final_df[['Sales']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, \n",
    "                                                    y, \n",
    "                                                    test_size=0.2, \n",
    "                                                    random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestRegressor(n_estimators=100, \n",
    "                           min_samples_leaf=3, \n",
    "                           max_depth=5, \n",
    "                           random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-35-168a6fc83696>:1: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  rf.fit(X_train, y_train)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
       "                      max_depth=5, max_features='auto', max_leaf_nodes=None,\n",
       "                      max_samples=None, min_impurity_decrease=0.0,\n",
       "                      min_impurity_split=None, min_samples_leaf=3,\n",
       "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "                      n_estimators=100, n_jobs=None, oob_score=False,\n",
       "                      random_state=42, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metric(preds, actuals):\n",
    "    preds = preds.reshape(-1)\n",
    "    actuals = actuals.reshape(-1)\n",
    "    assert preds.shape == actuals.shape\n",
    "    return 100 * np.linalg.norm((actuals - preds) / actuals) / np.sqrt(preds.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric for baseline prediction = 49.27381478129825\n"
     ]
    }
   ],
   "source": [
    "y_pred = rf.predict(X_test)\n",
    "\n",
    "rf_base_metric = metric(y_pred, y_test.values)\n",
    "\n",
    "print(\"Metric for baseline prediction = {}\".format(rf_base_metric))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
